了解！いただいたプロトコルに合わせて、計測ソフトの要件を**v0.2**にアップデートしました。これで現場運用（70名規模、強い情動刺激・停止動線・同意管理）に耐える一式になります。

# 実験用アケコン計測ソフト 要件定義書 v0.2

## 1. 目的・範囲（更新）

* 「自己顔条件（モーフ有）」と「非合成条件（モーフ無）」で、**情動覚醒/評価/回避・共感行動**への影響を定量化。
* **最小運用構成**で「説明→同意→キャリブ→実験→休憩→自由記述→RTA/面接→デブリーフ」を**一気通貫**で実施・記録。
* 70名規模の\*\*順序カウンタバランス（ラテン方格）\*\*と、**途中停止・撤退動線**をアプリ側でサポート。

## 2. 参加者・セッション設計

* 参加者ID（PID）を起点に**自動で順序割付（ラテン方格）**。
* 条件要素：

  * シーン3種（例：原爆前／原爆／原爆後）×各**A/B素材**
  * **モーフ有/無**（実験者が手動管理、アプリは**状態トグル＋遮蔽機能**を提供）
  * **再生順**：①3×2=6本の**完全ラテン** or ②「シーン順固定（前→中→後）」×**A/Bのみラテン**（選択可）

## 3. 機能要件（FR）

### FR-0 倫理・安全（新規）

* **同意UI**：目的／強い刺激の明示／中断自由／保存期間・使用範囲・匿名化／映像権利の記載を表示し、チェックボックス全完了で進行可能。
* **緊急停止**：参加者(B2長押し)／実験者(Esc)で**即ブラックアウト＋録画継続可否選択**。終了フロー（席→静養席→スタッフ）を画面に案内表示。
* **早期終了**：その時点までを**安全保存→要約画面**。

### FR-1 入出力（拡張）

* Picoシリアル受信（100 Hz）、**キーフォールバック**。
* **カメラ2系統**録画（front/usb0）＋**音声録音**（RTA・面接用、WAV/48k）。
* **顔画像撮影**（frontカメラから静止画`face.jpg`保存。外部モーフツール用に縦横比・解像度テンプレ提示）。
* **モーフ状態トグル**（実験者GUI：On/Off）＋**遮蔽オーバーレイ**（On時に未モーフ素材区間は黒画面で覆う）。

### FR-2 画面フロー（更新）

1. **ホーム**：PID/条件入力、デバイス確認、順序プレビュー、空き容量チェック
2. **イントロダクション**：実験概要
3. **説明**：倫理・権利・同意チェック
4. **EDAキャリブ（60s）**：ベースライン測定（静止）→`baseline.json`保存
5. **顔画像撮影**（任意／モーフ用）
6. **事前説明動画**（原爆映像に関する注意喚起用）
7. **トレーニング**：レバー操作（**鑑賞中5段階**の付け方）、GSR表示確認
8. **本実験（6クリップ）**

   * **オンライン興奮度(5段階)**：UP/DOWNで1〜5を**常時更新**し記録（既定=3）。
   * **A/B×モーフ有無**：再生直前に**実験者がモーフ状態を確定**。
   * **再生後**：**感情価(5段階)** を**ポスト評価**（左右で選択、B1確定）。
   * **自動マーカー**：`clip_start/clip_end`、素材(A/B)、シーン、モーフ状態をeventsへ。
   * **休憩(30s)** 自動タイマ。
9. **自由記述フォーム**（後述の3設問）
10. **RTA（10min）**：再生プレイヤ（スクラブ・倍速・一時停止）、**音声録音**。
11. **面接メモ**（テキスト）＋チェックリスト（面接質問4本の回答要約）
12. **デブリーフィング**：説明動画（事後の文脈化）
13. **完了**：保存先・導出サマリ表示

### FR-3 描画・操作（拡張）

* **矢印＆B1/B2**の即時反映、**GSRバー**（baseline相対）。
* **オンライン5段階UI**：画面右上に現在値（1〜5）を大きく表示、最後の入力時刻も表示。
* **ポスト評価UI**：5択のハイライト＋確定アニメーション。
* **モーフオーバーレイ**：状態On時、未モーフ素材の区間に**黒幕**表示（ホットキー`H`で手動出し入れ可能）。

### FR-4 記録・保存（拡張）

```
data/
  {YYYYMMDD-HHMMSS}_{PID}/
    meta/session.json
    raw/serial.csv                    # U,D,L,R,B1,B2,GSR_u16 + pc_ns
    raw/events.jsonl                  # クリップ境界・モーフ状態・マーカー・停止等
    video/front.mp4, video/usb0.mp4   # 参加者映像
    audio/rta.wav                     # RTA音声
    sidecar/front_frames.csv, usb0_frames.csv
    stimuli/face.jpg                  # 顔画像（同意時のみ）
    forms/free_text.json              # 自由記述
    forms/interview.json              # RTA/面接メモ
    derived/baseline.json             # EDA基準
    logs/app.log
```

* **serial.csv**：`pc_ns,pico_ts_ms,idx,U,D,L,R,B1,B2,GSR_u16, online5`
* **events.jsonl（例）**

  ```json
  {"pc_ns":..., "type":"clip_start","scene":"pre","ab":"A","morph":true,"clip_id":"pre_A"}
  {"pc_ns":..., "type":"online5_change","value":4}
  {"pc_ns":..., "type":"post_valence","value":2,"clip_id":"pre_A"}
  {"pc_ns":..., "type":"clip_end","clip_id":"pre_A","dur_s":92.5}
  {"pc_ns":..., "type":"pause_or_stop","reason":"participant_stop"}
  ```
* **free\_text.json**：

  * Q1: この体験を**色・温度・質感**で例えると？（自由記述）
  * Q2: **いまの気持ち**を表す三つの語
  * Q3: **未来の自分/まだ見ていない誰かへ手紙**（2–3行）
* **interview\.json**：

  * RTA音声のファイル名・開始/終了、**参照した時刻(mm\:ss)**、メモ
  * 面接4問の要約テキスト

### FR-5 同期・カウンタバランス（更新）

* **ラテン方格ジェネレータ**：PIDから**決定的**に6本の順序・A/Bを算出。
* オプションで\*\*「シーン順固定＋A/Bのみラテン」\*\*モードに切替。
* 同期基準はPCの`perf_counter_ns()`。クリップ境界と評価時刻を**同一時系列**で突合できる。

### FR-6 解析補助（H1/H2のためのエクスポート）

* **オフライン集計スクリプト**（同梱）：

  * クリップ単位の**レバーAUC**（オンライン5の積分/標準化）
  * EDAの**ΔSCL**（clip内平均−baseline）
  * **SCR頻度**（簡易：d(EDA)>θ検出/分）
  * **レバー×EDAの相互相関**（±5sでmax相関とラグ）
  * 出力：`derived/metrics_{PID}.csv`
* 閾値や窓長は`metrics.yaml`で調整可能（再現性担保）。

## 4. 非機能要件（NFR）変更点

* **連続運用**：70名×（1名あたり最大 \~45–60分）を想定。セッション切替を**3クリック以内**。
* **ドロップ耐性**：録画/音声/シリアルは**独立スレッド**で継続。どれかが落ちても他は保存。
* **セーフガード**：録画前に**空き容量**チェック（閾値下回りで開始不可）。

## 5. アーキテクチャ差分

* UI：**PySide6**本線（QtMultimediaで動画再生・プレビュー、もしくはOpenCV→Qt描画）。
* 追加ワーカー：`AudioRecorder`, `StimuliPlayer`, `ScheduleManager(LatinSquare)`.
* **遮蔽オーバーレイ**はUI層で最前面レイヤ。

## 6. コンテンツ管理

* `assets/config.yaml`で、**説明動画**、**各クリップ(A/B)**、**デブリーフ動画**の**ファイルパス**を管理。
* クリップごとに`scene`/`ab`/`duration_s`/`morph_required`フラグを定義可能。
* モーフ必須区間で未モーフが来た場合、**自動で黒幕**（実験者が解除可）。

## 7. 受け入れ基準（抜粋・追加）

* A-6：**オンライン5段階**が再生中に滑らかに記録され、**ポスト感情価**が保存される。
* A-7：**ラテン方格**がPIDから一貫して再現。
* A-8：**RTA音声**と**参照時刻**が紐づき保存。
* A-9：**停止操作**で即遮蔽され、ファイルは破損なくクローズ。
* A-10：`metrics_{PID}.csv`がH1/H2の**必要列**（AUC, ΔSCL, SCR/min, xcorr\_max, lag\_s）を出力。

## 8. オープン事項（決めたい）

1. **順序方式**：

   * 6本**完全ラテン**／「**シーン順固定＋A/Bのみラテン**」どちらで運用しますか？
2. **モーフ統制**：

   * 「モーフ有」セッションでは**全区間モーフ必須**／**一部のみ**？（一部なら**自動遮蔽規則**が必要）
3. **RTA**：

   * 参加者の**顔映像＋音声**を同時に撮りますか？（顔は既に録画済みだが、RTA中の**別音声**だけでも可）
4. **表情推定**：

   * OpenFace等の**後処理**を**内蔵バッチ**でキックするか、**外部手順**に留めるか。
5. **オンライン5段階の操作感**：

   * 現状は**UP/DOWNで1段階刻み、既定3**。変更希望ありますか？
6. **説明/同意テンプレ**：

   * 文面は**貴チーム版**をそのまま画面表示でOK？（PDF保管の要否）

## 9. 開発マイルストーン（更新）

* **M1**：同意→キャリブ→1クリップ再生→オンライン5段階→ポスト評価→保存
* **M2**：6本スケジューラ（ラテン方格）＋自動マーカー
* **M3**：2カメ録画＋RTA音声録音＋自由記述フォーム
* **M4**：モーフトグル＋遮蔽オーバーレイ＋緊急停止
* **M5**：オフライン集計スクリプト（AUC/ΔSCL/SCR/相関）
* **M6**：運用テレメトリ・ログ整備（落下検出、空き容量ガード、要約リポート）

---

このv0.2で**実験手順とH1/H2の検証要件がソフトに直結**しました。
上の**オープン事項**だけ決めてもらえれば、その前提で**M1〜M2の実装スケルトン**（PySide6プロジェクト・フォルダ構成・主要クラス・ダミー再生・保存系）を出します。どっちの順序方式で行きます？（私は「**シーン順固定＋A/Bラテン**」推し：参加者体験の文脈が保てて、統制もしやすいです）
